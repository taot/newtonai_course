{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096ac818-59de-43eb-9085-591aa515f8bc",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9330fb10-733e-4acd-bf80-be84ba9de3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fddb39ec774e3799ac446d8d974964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'}]}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b2ab7-b5ad-4410-abbb-c18bdf4abd5d",
   "metadata": {},
   "source": [
    "# 分词器 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15ed149-fa8e-42b1-9a38-f0f1b68f1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c213f05-a50b-4ed2-8a8e-e7bb47d10821",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODLE_BASE_DIR = \"/workspace/.hf_home/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d826713-ef2f-462b-bff2-762eeb70b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODLE_BASE_DIR\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "torch_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7700d4-7fa8-4e48-9412-7c1998a57878",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de51f2-51e3-4c8c-b72c-42614405fe0c",
   "metadata": {},
   "source": [
    "# 读取模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32ca2e59-eed7-4e04-a0aa-ee6a790b5908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106b98d4d2a24bdc8b8d48a9c83be2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch_dtype)\n",
    "model_m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2fb7b5a-cadd-4533-92fa-2ecd3fa412bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "227b6cb1-c163-4262-a6d3-3bcaa7f6587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"_name_or_path\": \"/workspace/.hf_home/hub/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "        \"LlamaForCausalLM\"\n",
      "    ],\n",
      "    \"attention_bias\": false,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 128000,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"dtype\": \"bfloat16\",\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": [\n",
      "        128001,\n",
      "        128008,\n",
      "        128009\n",
      "    ],\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"head_dim\": 128,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 3072,\n",
      "    \"id2label\": {\n",
      "        \"0\": \"LABEL_0\",\n",
      "        \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 8192,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "        \"LABEL_0\": 0,\n",
      "        \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 131072,\n",
      "    \"min_length\": 0,\n",
      "    \"mlp_bias\": false,\n",
      "    \"model_type\": \"llama\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 24,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 28,\n",
      "    \"num_key_value_heads\": 8,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"pretraining_tp\": 1,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"rms_norm_eps\": 1e-05,\n",
      "    \"rope_scaling\": {\n",
      "        \"factor\": 32.0,\n",
      "        \"high_freq_factor\": 4.0,\n",
      "        \"low_freq_factor\": 1.0,\n",
      "        \"original_max_position_embeddings\": 8192,\n",
      "        \"rope_type\": \"llama3\"\n",
      "    },\n",
      "    \"rope_theta\": 500000.0,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.56.0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 128256\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 模型配置参数\n",
    "config = model_m.config.to_dict()\n",
    "print(json.dumps(dict(sorted(config.items())), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb5a5486-3cdf-4c1f-adc1-85aa739420ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = config[\"hidden_size\"]\n",
    "n_layers = config[\"num_hidden_layers\"]\n",
    "n_heads = config[\"num_attention_heads\"]\n",
    "n_kv_heads = config[\"num_key_value_heads\"]\n",
    "vocab_size = config[\"vocab_size\"]\n",
    "norm_eps = config[\"rms_norm_eps\"]\n",
    "rope_theta = torch.tensor(config[\"rope_theta\"])\n",
    "\n",
    "group_heads = n_heads // n_kv_heads\n",
    "dk = dim // n_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f730687-4be3-4bd6-a6a0-7c98d0a3762a",
   "metadata": {},
   "source": [
    "# 文本分词编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dac52c0-b566-42f0-b5b2-e6ebdd8ec32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"测试中，用中文说成语，前程似锦，金榜题\"\n",
    "# prompt = \"中华人民万\"\n",
    "# prompt = \"星期\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa02b5db-2e64-45bc-9ae1-f903aae2c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128000, 82805, 16325, 119977, 108891, 37687, 13153, 73981, 3922, 25580, 39607, 104409, 127999, 3922, 35330, 121272, 34972]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "print(tokens)\n",
    "tokens = torch.tensor(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a8c4705-9aaf-4ac9-859a-ff2831cb33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>', '测试', '中', '，用', '中文', '说', '成', '语', '，', '前', '程', '似', '锦', '，', '金', '榜', '题']\n"
     ]
    }
   ],
   "source": [
    "prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens]\n",
    "print(prompt_split_as_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03e1c9-c989-4126-b484-d9ff880b3f19",
   "metadata": {},
   "source": [
    "# Token embedding 嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb3d14b4-b426-4b6c-b124-b4187fb4de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后输出的全连接层\n",
    "lm_head = model[\"lm_head.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c700589c-18e2-4f2c-846f-70b00874a665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1292e-02,  9.9487e-03,  1.4160e-02,  ..., -3.5706e-03,\n",
       "         -1.9775e-02,  5.3711e-03],\n",
       "        [ 1.3245e-02, -3.8385e-05,  2.2461e-02,  ..., -2.6550e-03,\n",
       "          3.1738e-02, -1.0681e-03],\n",
       "        [ 1.9775e-02,  2.0020e-02,  2.8687e-02,  ..., -3.5248e-03,\n",
       "          3.1433e-03, -7.6294e-03],\n",
       "        ...,\n",
       "        [-3.0975e-03,  2.1057e-03,  4.8828e-03,  ..., -2.0905e-03,\n",
       "         -1.2207e-03, -2.8992e-03],\n",
       "        [-3.0975e-03,  2.1057e-03,  4.8828e-03,  ..., -2.0905e-03,\n",
       "         -1.2207e-03, -2.8992e-03],\n",
       "        [-3.0975e-03,  2.1057e-03,  4.8828e-03,  ..., -2.0905e-03,\n",
       "         -1.2207e-03, -2.8992e-03]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载嵌入层\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, dim)\n",
    "embedding_layer.weight.data.copy_(model[\"model.embed_tokens.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fc1d220-142a-460c-bbed-241c22d839b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 3072])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings_unnormalized = embedding_layer(tokens).to(torch_dtype).to(device)\n",
    "print(token_embeddings_unnormalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbba8de-3e65-4f4a-87e0-d14f1a75f424",
   "metadata": {},
   "source": [
    "# RMS 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c330adb-ff10-4990-9f92-4ac2ea37163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_norm(tensor, norm_weights):\n",
    "    r_rms = torch.rsqrt(tensor.pow(2).mean(-1, keepdim=True) + norm_eps)\n",
    "    x = (tensor * r_rms) * norm_weights\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d2504e8-07ed-46f2-b6c5-4f9f8313c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 3072])\n"
     ]
    }
   ],
   "source": [
    "# 测试归一化\n",
    "token_embeddings = rms_norm(token_embeddings_unnormalized, model[\"model.layers.0.input_layernorm.weight\"])\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e9fd3-15f3-4c83-9513-8b4fc589e4e0",
   "metadata": {},
   "source": [
    "# 实现注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90014431-ce0b-48f1-9c4d-020bcac8a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3072]) torch.Size([1024, 3072]) torch.Size([1024, 3072]) torch.Size([3072, 3072])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    model[\"model.layers.0.self_attn.q_proj.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.k_proj.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.v_proj.weight\"].shape,\n",
    "    model[\"model.layers.0.self_attn.o_proj.weight\"].shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4907c5c-0149-4ebd-91e4-6bcd12ec8fdb",
   "metadata": {},
   "source": [
    "## 计算 query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5979fa4-0ad3-42a7-b392-3eafa93c25ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 128, 3072])\n"
     ]
    }
   ],
   "source": [
    "q_layer0 = model[\"model.layers.0.self_attn.q_proj.weight\"]\n",
    "head_dim = q_layer0.shape[0] // n_heads\n",
    "q_layer0 = q_layer0.view(n_heads, head_dim, dim)\n",
    "print(q_layer0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c375265-122a-4079-b947-49287006a2da",
   "metadata": {},
   "source": [
    "## 第一层的第一个头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55d38dbc-0990-4e40-9164-6e3512a40530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3072])\n"
     ]
    }
   ],
   "source": [
    "q_layer0_head0 = q_layer0[0]\n",
    "print(q_layer0_head0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d41927-b6c4-4454-84d4-164915483547",
   "metadata": {},
   "source": [
    "## q_per_token = torch.matmul(token_embeddings, q_layer0_head0.T)\n",
    "print(q_per_token.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
